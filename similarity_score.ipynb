{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c993719",
   "metadata": {},
   "source": [
    "### Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c5c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_books = pd.read_csv('books_clean.csv')\n",
    "df_authors = pd.read_csv('authors_clean.csv')\n",
    "df_reviews = pd.read_csv('reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d495a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'description', 'authors', 'image', 'previewLink', 'publisher',\n",
      "       'publishedDate', 'infoLink', 'categories', 'main_author', 'genre',\n",
      "       'review_count', 'avg_rating', 'is_indie'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>main_author</th>\n",
       "      <th>genre</th>\n",
       "      <th>review_count</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>is_indie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>Philip Nel</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>9</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>self-published</td>\n",
       "      <td>2000</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>David R Ray</td>\n",
       "      <td>Religion</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>Veronica Haddon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>32</td>\n",
       "      <td>3.718750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Church of Christ: A Biblical Ecclesiology ...</td>\n",
       "      <td>In The Church of Christ: A Biblical Ecclesiolo...</td>\n",
       "      <td>['Everett Ferguson']</td>\n",
       "      <td>http://books.google.com/books/content?id=kVqRa...</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;p...</td>\n",
       "      <td>Wm. B. Eerdmans Publishing</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>Everett Ferguson</td>\n",
       "      <td>Religion</td>\n",
       "      <td>4</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saint Hyacinth of Poland</td>\n",
       "      <td>The story for children 10 and up of St. Hyacin...</td>\n",
       "      <td>['Mary Fabyan Windeatt']</td>\n",
       "      <td>http://books.google.com/books/content?id=lmLqA...</td>\n",
       "      <td>http://books.google.nl/books?id=lmLqAAAACAAJ&amp;d...</td>\n",
       "      <td>Tan Books &amp; Pub</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=lmLqAAAACAAJ&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>Mary Fabyan Windeatt</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                           Dr. Seuss: American Icon   \n",
       "1              Wonderful Worship in Smaller Churches   \n",
       "2                      Whispers of the Wicked Saints   \n",
       "3  The Church of Christ: A Biblical Ecclesiology ...   \n",
       "4                           Saint Hyacinth of Poland   \n",
       "\n",
       "                                         description  \\\n",
       "0  Philip Nel takes a fascinating look into the k...   \n",
       "1  This resource includes twelve principles in un...   \n",
       "2  Julia Thomas finds her life spinning out of co...   \n",
       "3  In The Church of Christ: A Biblical Ecclesiolo...   \n",
       "4  The story for children 10 and up of St. Hyacin...   \n",
       "\n",
       "                    authors  \\\n",
       "0            ['Philip Nel']   \n",
       "1           ['David R Ray']   \n",
       "2       ['Veronica Haddon']   \n",
       "3      ['Everett Ferguson']   \n",
       "4  ['Mary Fabyan Windeatt']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=IjvHQ...   \n",
       "1  http://books.google.com/books/content?id=2tsDA...   \n",
       "2  http://books.google.com/books/content?id=aRSIg...   \n",
       "3  http://books.google.com/books/content?id=kVqRa...   \n",
       "4  http://books.google.com/books/content?id=lmLqA...   \n",
       "\n",
       "                                         previewLink  \\\n",
       "0  http://books.google.nl/books?id=IjvHQsCn_pgC&p...   \n",
       "1  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "2  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "3  http://books.google.nl/books?id=kVqRaiPlx88C&p...   \n",
       "4  http://books.google.nl/books?id=lmLqAAAACAAJ&d...   \n",
       "\n",
       "                    publisher publishedDate  \\\n",
       "0                   A&C Black    2005-01-01   \n",
       "1              self-published          2000   \n",
       "2                   iUniverse       2005-02   \n",
       "3  Wm. B. Eerdmans Publishing          1996   \n",
       "4             Tan Books & Pub    2009-01-01   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "1  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "2  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "3  http://books.google.nl/books?id=kVqRaiPlx88C&d...   \n",
       "4  http://books.google.nl/books?id=lmLqAAAACAAJ&d...   \n",
       "\n",
       "                      categories           main_author  \\\n",
       "0  ['Biography & Autobiography']            Philip Nel   \n",
       "1                   ['Religion']           David R Ray   \n",
       "2                    ['Fiction']       Veronica Haddon   \n",
       "3                   ['Religion']      Everett Ferguson   \n",
       "4  ['Biography & Autobiography']  Mary Fabyan Windeatt   \n",
       "\n",
       "                       genre  review_count  avg_rating  is_indie  \n",
       "0  Biography & Autobiography             9    4.555556     False  \n",
       "1                   Religion             4    5.000000      True  \n",
       "2                    Fiction            32    3.718750     False  \n",
       "3                   Religion             4    4.500000     False  \n",
       "4  Biography & Autobiography             2    4.500000     False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_books.columns) \n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205d8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['main_author', 'total_books', 'total_reviews', 'is_self_published',\n",
      "       'is_indie'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_author</th>\n",
       "      <th>total_books</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>is_self_published</th>\n",
       "      <th>is_indie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Dr) Seuss</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Augustine</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blizzard Entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deiss</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meystre-Sargent</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               main_author  total_books  total_reviews  is_self_published  \\\n",
       "0               (Dr) Seuss            1              3               True   \n",
       "1                Augustine            1              1              False   \n",
       "2   Blizzard Entertainment            1             13              False   \n",
       "3                    Deiss            1              9              False   \n",
       "4          Meystre-Sargent            1              2              False   \n",
       "\n",
       "   is_indie  \n",
       "0      True  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_authors.columns)\n",
    "df_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c10e3967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ISBN', 'Title', 'rating', 'review_text'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Title</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Dr. Seuss: American Icon\" by Philip Nel is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                     Title  rating  \\\n",
       "0  0826414346  Dr. Seuss: American Icon     5.0   \n",
       "1  0826414346  Dr. Seuss: American Icon     5.0   \n",
       "2  0826414346  Dr. Seuss: American Icon     4.0   \n",
       "3  0826414346  Dr. Seuss: American Icon     4.0   \n",
       "4  0826414346  Dr. Seuss: American Icon     4.0   \n",
       "\n",
       "                                         review_text  \n",
       "0  I don't care much for Dr. Seuss but after read...  \n",
       "1  If people become the books they read and if \"t...  \n",
       "2  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "3  Philip Nel - Dr. Seuss: American IconThis is b...  \n",
       "4  \"Dr. Seuss: American Icon\" by Philip Nel is a ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_reviews.columns)\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41c6a4",
   "metadata": {},
   "source": [
    "## Indie book recommendations with TF‑IDF + cosine similarity\n",
    "\n",
    "We’ll recommend indie books based on textual similarity of reviews.\n",
    "\n",
    "High‑level steps:\n",
    "- Normalize titles to improve joins.\n",
    "- Aggregate all review texts per book (Title).\n",
    "- Build a TF‑IDF matrix of these texts.\n",
    "- Given 2–3 favorite titles, average their TF‑IDF vectors to form a “preference vector”.\n",
    "- Compute cosine similarity between this vector and all books, then return the top indie titles only.\n",
    "\n",
    "Notes:\n",
    "- If a book has no reviews, we’ll optionally fall back to its description to avoid empty text.\n",
    "- Favorites not found (or with no text) are ignored with a warning.\n",
    "- We exclude the input favorites from the final results by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3521683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for modeling and utilities\n",
    "import numpy as np\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"scikit-learn is not available. Please install it to run the recommender.\")\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "import re\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e26ffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared text for 141755 books; indie count in this set: 17667\n"
     ]
    }
   ],
   "source": [
    "# Prepare aggregated review text per Title and join with books\n",
    "def _normalize_title(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "# Create normalized keys for joining\n",
    "df_books['Title_norm'] = df_books['Title'].apply(_normalize_title)\n",
    "df_reviews['Title_norm'] = df_reviews['Title'].apply(_normalize_title)\n",
    "\n",
    "# Aggregate review texts by Title\n",
    "agg_reviews = (\n",
    "    df_reviews\n",
    "    .dropna(subset=['review_text'])\n",
    "    .groupby('Title_norm', as_index=False)\n",
    "    .agg({\n",
    "        'review_text': lambda s: \" \\n\".join(map(str, s)),\n",
    "        'rating': 'mean'\n",
    "    })\n",
    "    .rename(columns={'rating': 'avg_review_rating_from_reviews'})\n",
    ")\n",
    "\n",
    "# Merge with books; keep description and aggregated review text separate\n",
    "df_books_text = df_books.merge(agg_reviews, on='Title_norm', how='left')\n",
    "df_books_text['review_text_agg'] = df_books_text['review_text'].fillna(\"\")\n",
    "df_books_text['desc_text'] = df_books_text['description'].fillna(\"\")\n",
    "\n",
    "# Optional: enrich review text with description if reviews are sparse (so review side isn't empty)\n",
    "mask_sparse_reviews = df_books_text['review_text_agg'].str.len() < 50\n",
    "df_books_text.loc[mask_sparse_reviews, 'review_text_agg'] = (\n",
    "    df_books_text.loc[mask_sparse_reviews, 'review_text_agg'] +\n",
    "    \" \\n\" + df_books_text.loc[mask_sparse_reviews, 'desc_text'].astype(str)\n",
    ")\n",
    "\n",
    "# Keep only rows with some text on at least description OR reviews\n",
    "has_any_text = (df_books_text['desc_text'].str.strip().str.len() > 0) | (df_books_text['review_text_agg'].str.strip().str.len() > 0)\n",
    "df_books_text = df_books_text[has_any_text].reset_index(drop=True)\n",
    "\n",
    "# Helpers and info\n",
    "is_indie_mask = df_books_text['is_indie'] == True\n",
    "print(f\"Prepared text for {len(df_books_text)} books; indie count in this set: {int(is_indie_mask.sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e85116c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reduced matrices from .npy files\n",
      "SVD(desc) shape: (141755, 300)\n",
      "SVD(rev) shape: (141755, 300)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"models\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Try to load precomputed reduced matrices and pipeline if available.\n",
    "loaded = False\n",
    "desc_reduced_path = OUT_DIR / \"X_desc_reduced.npy\"\n",
    "rev_reduced_path = OUT_DIR / \"X_review_reduced.npy\"\n",
    "npz_path = OUT_DIR / \"reduced_matrices.npz\"\n",
    "tfidf_desc_path = OUT_DIR / \"tfidf_desc.joblib\"\n",
    "svd_desc_path = OUT_DIR / \"svd_desc.joblib\"\n",
    "tfidf_rev_path = OUT_DIR / \"tfidf_rev.joblib\"\n",
    "svd_rev_path = OUT_DIR / \"svd_rev.joblib\"\n",
    "title_map_path = OUT_DIR / \"title_norm_to_row.json\"\n",
    "df_parquet_path = OUT_DIR / \"df_books_text.parquet\"\n",
    "\n",
    "if npz_path.exists():\n",
    "    print(\"Loading reduced matrices from compressed npz:\", npz_path)\n",
    "    with np.load(npz_path) as data:\n",
    "        X_desc_reduced = data[\"X_desc\"]\n",
    "        X_review_reduced = data[\"X_review\"]\n",
    "    loaded = True\n",
    "elif desc_reduced_path.exists() and rev_reduced_path.exists():\n",
    "    print(\"Loading reduced matrices from .npy files\")\n",
    "    X_desc_reduced = np.load(desc_reduced_path)\n",
    "    X_review_reduced = np.load(rev_reduced_path)\n",
    "    loaded = True\n",
    "\n",
    "if loaded:\n",
    "    # attempt to load vectorizers + SVDs if present (optional but recommended)\n",
    "    try:\n",
    "        if tfidf_desc_path.exists(): tfidf_desc = joblib.load(tfidf_desc_path)\n",
    "        else: tfidf_desc = None\n",
    "        if svd_desc_path.exists(): svd_desc = joblib.load(svd_desc_path)\n",
    "        else: svd_desc = None\n",
    "        if tfidf_rev_path.exists(): tfidf_rev = joblib.load(tfidf_rev_path)\n",
    "        else: tfidf_rev = None\n",
    "        if svd_rev_path.exists(): svd_rev = joblib.load(svd_rev_path)\n",
    "        else: svd_rev = None\n",
    "    except Exception as e:\n",
    "        print(\"Warning: failed to load some pipeline objects:\", e)\n",
    "        tfidf_desc = tfidf_desc if 'tfidf_desc' in globals() else None\n",
    "        svd_desc = svd_desc if 'svd_desc' in globals() else None\n",
    "        tfidf_rev = tfidf_rev if 'tfidf_rev' in globals() else None\n",
    "        svd_rev = svd_rev if 'svd_rev' in globals() else None\n",
    "\n",
    "    # load supporting assets if available\n",
    "    if title_map_path.exists():\n",
    "        with open(title_map_path, \"r\") as f:\n",
    "            title_norm_to_row = json.load(f)\n",
    "    if df_parquet_path.exists():\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            df_books_text = pd.read_parquet(df_parquet_path)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: failed to load df_books_text.parquet:\", e)\n",
    "\n",
    "    print(f\"SVD(desc) shape: {X_desc_reduced.shape}\")\n",
    "    print(f\"SVD(rev) shape: {X_review_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51f8f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF(desc) shape: (141755, 50000)\n",
      "TF-IDF(rev) shape: (141755, 30000)\n",
      "SVD(desc) shape: (141755, 300)\n",
      "SVD(rev) shape: (141755, 300)\n"
     ]
    }
   ],
   "source": [
    "# Build TF-IDF matrices for description and reviews, then enforce SVD reduction\n",
    "if not SKLEARN_AVAILABLE:\n",
    "    raise RuntimeError(\"scikit-learn is required to build TF-IDF. Please install scikit-learn.\")\n",
    "\n",
    "# TF-IDF on description (heavier weight later)\n",
    "tfidf_desc = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    ngram_range=(1,1),\n",
    "    max_features=50000,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "X_desc = tfidf_desc.fit_transform(df_books_text['desc_text'])\n",
    "print(f\"TF-IDF(desc) shape: {X_desc.shape}\")\n",
    "\n",
    "# TF-IDF on reviews (supportive feature)\n",
    "tfidf_rev = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    ngram_range=(1,1),\n",
    "    max_features=30000,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "X_rev = tfidf_rev.fit_transform(df_books_text['review_text_agg'])\n",
    "print(f\"TF-IDF(rev) shape: {X_rev.shape}\")\n",
    "\n",
    "# Mapping: normalized title -> row index for robust lookups\n",
    "title_norm_to_row = {t: i for i, t in enumerate(df_books_text['Title_norm'])}\n",
    "\n",
    "# Enforce SVD dimensionality reduction before recommendations\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "USE_SVD = True\n",
    "SVD_COMPONENTS = 300\n",
    "\n",
    "# SVD reduce description\n",
    "svd_desc = TruncatedSVD(n_components=max(2, min(SVD_COMPONENTS, X_desc.shape[1]-1)), random_state=42)\n",
    "X_desc_reduced = svd_desc.fit_transform(X_desc)\n",
    "X_desc_reduced = X_desc_reduced / (np.linalg.norm(X_desc_reduced, axis=1, keepdims=True) + 1e-12)\n",
    "print(f\"SVD(desc) shape: {X_desc_reduced.shape}\")\n",
    "\n",
    "# SVD reduce reviews\n",
    "svd_rev = TruncatedSVD(n_components=max(2, min(SVD_COMPONENTS, X_rev.shape[1]-1)), random_state=42)\n",
    "X_review_reduced = svd_rev.fit_transform(X_rev)\n",
    "X_review_reduced = X_review_reduced / (np.linalg.norm(X_review_reduced, axis=1, keepdims=True) + 1e-12)\n",
    "print(f\"SVD(rev) shape: {X_review_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ecee1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define recommender with genre constraint and indie boost\n",
    "GENRE_WEIGHT = 0.6   # genre/description importance dominates\n",
    "REVIEW_WEIGHT = 0.4  # reviews supportive\n",
    "INDIE_BOOST = 0.1   # additive boost for indie titles\n",
    "\n",
    "# Helper: normalize genre tokens\n",
    "def _norm_genre_list(x):\n",
    "    if isinstance(x, str):\n",
    "        s = x.lower()\n",
    "        parts = re.split(r\"[;,]\", s)\n",
    "        return {p.strip() for p in parts if p.strip()}\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return {str(p).strip().lower() for p in x if str(p).strip()}\n",
    "    return set()\n",
    "\n",
    "def recommend_indie_books(favorite_titles: List[str], top_k: int = 10, exclude_favorites: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recommend books prioritizing genre/description similarity, then reviews; enforce genre match; boost indie.\n",
    "    If no overlapping genre exists with favorites, fall back to closest overall by combined score.\n",
    "    \"\"\"\n",
    "    # Ensure reductions exist\n",
    "    for var in ['X_desc_reduced', 'X_review_reduced']:\n",
    "        if var not in globals() or globals()[var] is None:\n",
    "            raise RuntimeError(\"SVD reduction required. Run the TF-IDF + SVD cell first.\")\n",
    "\n",
    "    norm_favs = [_normalize_title(t) for t in favorite_titles]\n",
    "    indices = [title_norm_to_row.get(t) for t in norm_favs]\n",
    "    fav_idx = [i for i in indices if i is not None]\n",
    "    if not fav_idx:\n",
    "        print(\"No favorite titles found in the corpus. Check spelling or availability.\")\n",
    "        return pd.DataFrame(columns=['Title','similarity'])\n",
    "\n",
    "    # Build preference vectors (mean of favorites) and normalize\n",
    "    pref_desc = X_desc_reduced[fav_idx].mean(axis=0, keepdims=True)\n",
    "    pref_desc = pref_desc / (np.linalg.norm(pref_desc, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    pref_rev = X_review_reduced[fav_idx].mean(axis=0, keepdims=True)\n",
    "    pref_rev = pref_rev / (np.linalg.norm(pref_rev, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    # Compute cosine similarities via dot\n",
    "    sims_desc = (pref_desc @ X_desc_reduced.T).ravel()\n",
    "    sims_rev = (pref_rev @ X_review_reduced.T).ravel()\n",
    "\n",
    "    # Enforce genre match: only keep books sharing at least one genre term with ANY favorite\n",
    "    fav_genres_sets = []\n",
    "    for i in fav_idx:\n",
    "        fav_genres_sets.append(_norm_genre_list(df_books_text.loc[i, 'categories'] if 'categories' in df_books_text.columns else ''))\n",
    "    fav_genres_union = set().union(*fav_genres_sets) if fav_genres_sets else set()\n",
    "\n",
    "    book_genres = df_books_text['categories'].fillna(\"\").apply(_norm_genre_list)\n",
    "    genre_match_mask = book_genres.apply(lambda g: len(g.intersection(fav_genres_union)) > 0)\n",
    "\n",
    "    # Combine scores with weights and indie boost\n",
    "    combined = GENRE_WEIGHT * sims_desc + REVIEW_WEIGHT * sims_rev\n",
    "    indie_mask = (df_books_text['is_indie'] == True)\n",
    "    combined = combined + INDIE_BOOST * indie_mask.values.astype(float)\n",
    "\n",
    "    # Prepare results\n",
    "    result = df_books_text.copy()\n",
    "    result['similarity'] = combined\n",
    "\n",
    "    # Align genre mask to current result and apply; if none matched, fall back to overall similarity\n",
    "    aligned_mask = genre_match_mask.reindex(result.index, fill_value=False)\n",
    "    if aligned_mask.any():\n",
    "        result = result[aligned_mask.to_numpy()]\n",
    "    else:\n",
    "        print(\"No overlapping genres found; falling back to closest overall matches by score.\")\n",
    "\n",
    "    if exclude_favorites:\n",
    "        result = result[~result['Title_norm'].isin(norm_favs)]\n",
    "\n",
    "    # Sort by similarity and return top_k\n",
    "    cols = ['Title','main_author','avg_rating','is_indie','genre','categories','similarity','previewLink','infoLink']\n",
    "    existing_cols = [c for c in cols if c in result.columns]\n",
    "    return result.sort_values(by='similarity', ascending=False)[existing_cols].head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a655628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favorites used for demo: ['Dr. Seuss: American Icon']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>main_author</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>is_indie</th>\n",
       "      <th>genre</th>\n",
       "      <th>categories</th>\n",
       "      <th>similarity</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>infoLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99427</th>\n",
       "      <td>Dr Frau</td>\n",
       "      <td>Grace H Kaiser</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.391327</td>\n",
       "      <td>http://books.google.com/books?id=5gnVw-m09VAC&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=5gnVw-m09VAC&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>American Thunder : The Garth Brooks Story</td>\n",
       "      <td>Jo Sgammato</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.386587</td>\n",
       "      <td>http://books.google.nl/books?id=czUr32l5PDsC&amp;q...</td>\n",
       "      <td>http://books.google.nl/books?id=czUr32l5PDsC&amp;d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102558</th>\n",
       "      <td>The Fame of a Dead Man's Deeds: An Up-Close Po...</td>\n",
       "      <td>Robert S Griffin</td>\n",
       "      <td>4.769231</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.386360</td>\n",
       "      <td>http://books.google.com/books?id=9Se8wAEACAAJ&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=9Se8wAEACAAJ&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48241</th>\n",
       "      <td>The Three Roosevelts: Patrician Leaders Who Tr...</td>\n",
       "      <td>James Macgregor Burns</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.384322</td>\n",
       "      <td>http://books.google.com/books?id=MxOUYEy6iykC&amp;...</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49308</th>\n",
       "      <td>Satchmo - My Life in New Orleans</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.381470</td>\n",
       "      <td>http://books.google.com/books?id=S7TSDQAAQBAJ&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=S7TSDQAAQBAJ&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128986</th>\n",
       "      <td>Satchmo: My life in new Orleans</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.381470</td>\n",
       "      <td>http://books.google.com/books?id=S7TSDQAAQBAJ&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=S7TSDQAAQBAJ&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86758</th>\n",
       "      <td>America's political dynasties</td>\n",
       "      <td>Stephen Hess</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.369352</td>\n",
       "      <td>http://books.google.nl/books?id=_fV5rgEACAAJ&amp;d...</td>\n",
       "      <td>http://books.google.nl/books?id=_fV5rgEACAAJ&amp;d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114421</th>\n",
       "      <td>Remembering Charles Kuralt</td>\n",
       "      <td>Ralph Grizzle</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.368745</td>\n",
       "      <td>http://books.google.com/books?id=NP0aAQAAIAAJ&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=NP0aAQAAIAAJ&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136899</th>\n",
       "      <td>Long March to Freedom: Tom Hargrove's Own Stor...</td>\n",
       "      <td>Thomas R Hargrove</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.368412</td>\n",
       "      <td>http://books.google.com/books?id=gF7RAAAACAAJ&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=gF7RAAAACAAJ&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130292</th>\n",
       "      <td>World within world: The autobiography of Steph...</td>\n",
       "      <td>Stephen Spender</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>True</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>0.367292</td>\n",
       "      <td>http://books.google.com/books?id=wLqLtwEACAAJ&amp;...</td>\n",
       "      <td>http://books.google.com/books?id=wLqLtwEACAAJ&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title  \\\n",
       "99427                                             Dr Frau   \n",
       "11051           American Thunder : The Garth Brooks Story   \n",
       "102558  The Fame of a Dead Man's Deeds: An Up-Close Po...   \n",
       "48241   The Three Roosevelts: Patrician Leaders Who Tr...   \n",
       "49308                    Satchmo - My Life in New Orleans   \n",
       "128986                    Satchmo: My life in new Orleans   \n",
       "86758                       America's political dynasties   \n",
       "114421                         Remembering Charles Kuralt   \n",
       "136899  Long March to Freedom: Tom Hargrove's Own Stor...   \n",
       "130292  World within world: The autobiography of Steph...   \n",
       "\n",
       "                  main_author  avg_rating  is_indie  \\\n",
       "99427          Grace H Kaiser    4.333333      True   \n",
       "11051             Jo Sgammato    4.533333      True   \n",
       "102558       Robert S Griffin    4.769231      True   \n",
       "48241   James Macgregor Burns    4.000000      True   \n",
       "49308         Louis Armstrong    4.857143      True   \n",
       "128986        Louis Armstrong    4.857143      True   \n",
       "86758            Stephen Hess    5.000000      True   \n",
       "114421          Ralph Grizzle    4.666667      True   \n",
       "136899      Thomas R Hargrove    4.000000      True   \n",
       "130292        Stephen Spender    4.800000      True   \n",
       "\n",
       "                            genre                     categories  similarity  \\\n",
       "99427   Biography & Autobiography  ['Biography & Autobiography']    0.391327   \n",
       "11051   Biography & Autobiography  ['Biography & Autobiography']    0.386587   \n",
       "102558  Biography & Autobiography  ['Biography & Autobiography']    0.386360   \n",
       "48241   Biography & Autobiography  ['Biography & Autobiography']    0.384322   \n",
       "49308   Biography & Autobiography  ['Biography & Autobiography']    0.381470   \n",
       "128986  Biography & Autobiography  ['Biography & Autobiography']    0.381470   \n",
       "86758   Biography & Autobiography  ['Biography & Autobiography']    0.369352   \n",
       "114421  Biography & Autobiography  ['Biography & Autobiography']    0.368745   \n",
       "136899  Biography & Autobiography  ['Biography & Autobiography']    0.368412   \n",
       "130292  Biography & Autobiography  ['Biography & Autobiography']    0.367292   \n",
       "\n",
       "                                              previewLink  \\\n",
       "99427   http://books.google.com/books?id=5gnVw-m09VAC&...   \n",
       "11051   http://books.google.nl/books?id=czUr32l5PDsC&q...   \n",
       "102558  http://books.google.com/books?id=9Se8wAEACAAJ&...   \n",
       "48241   http://books.google.com/books?id=MxOUYEy6iykC&...   \n",
       "49308   http://books.google.com/books?id=S7TSDQAAQBAJ&...   \n",
       "128986  http://books.google.com/books?id=S7TSDQAAQBAJ&...   \n",
       "86758   http://books.google.nl/books?id=_fV5rgEACAAJ&d...   \n",
       "114421  http://books.google.com/books?id=NP0aAQAAIAAJ&...   \n",
       "136899  http://books.google.com/books?id=gF7RAAAACAAJ&...   \n",
       "130292  http://books.google.com/books?id=wLqLtwEACAAJ&...   \n",
       "\n",
       "                                                 infoLink  \n",
       "99427   http://books.google.com/books?id=5gnVw-m09VAC&...  \n",
       "11051   http://books.google.nl/books?id=czUr32l5PDsC&d...  \n",
       "102558  http://books.google.com/books?id=9Se8wAEACAAJ&...  \n",
       "48241   https://play.google.com/store/books/details?id...  \n",
       "49308   http://books.google.com/books?id=S7TSDQAAQBAJ&...  \n",
       "128986  http://books.google.com/books?id=S7TSDQAAQBAJ&...  \n",
       "86758   http://books.google.nl/books?id=_fV5rgEACAAJ&d...  \n",
       "114421  http://books.google.com/books?id=NP0aAQAAIAAJ&...  \n",
       "136899  http://books.google.com/books?id=gF7RAAAACAAJ&...  \n",
       "130292  http://books.google.com/books?id=wLqLtwEACAAJ&...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indie in results: 10\n"
     ]
    }
   ],
   "source": [
    "# Example usage: ensure genre match and indie boost are applied\n",
    "example_favorites = [\n",
    "    df_books_text['Title'].iloc[0] if len(df_books_text) > 0 else 'Unknown',\n",
    "]\n",
    "print('Favorites used for demo:', example_favorites)\n",
    "try:\n",
    "    out = recommend_indie_books(example_favorites, top_k=10)\n",
    "    display(out)\n",
    "    print(\"Indie in results:\", int((out['is_indie'] == True).sum()))\n",
    "except Exception as e:\n",
    "    print(\"Recommendation failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d188a14-c970-4fd5-9465-fd57485291ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] Error writing bytes to file. Detail: [errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m joblib.dump(tfidf_rev, OUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mtfidf_rev.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m joblib.dump(svd_rev, OUT_DIR / \u001b[33m\"\u001b[39m\u001b[33msvd_rev.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mdf_books_text\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdf_books_text.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mtitle_norm_to_row.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     13\u001b[39m     json.dump({k: \u001b[38;5;28mint\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m title_norm_to_row.items()},f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/core/frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/io/parquet.py:482\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m impl = get_engine(engine)\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pandas/io/parquet.py:229\u001b[39m, in \u001b[36mPyArrowImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[38;5;28mself\u001b[39m.api.parquet.write_to_dataset(\n\u001b[32m    220\u001b[39m             table,\n\u001b[32m    221\u001b[39m             path_or_handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m             **kwargs,\n\u001b[32m    226\u001b[39m         )\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    228\u001b[39m         \u001b[38;5;66;03m# write to single output file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pyarrow/parquet/core.py:1983\u001b[39m, in \u001b[36mwrite_table\u001b[39m\u001b[34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **kwargs)\u001b[39m\n\u001b[32m   1956\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1957\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ParquetWriter(\n\u001b[32m   1958\u001b[39m             where, table.schema,\n\u001b[32m   1959\u001b[39m             filesystem=filesystem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1981\u001b[39m             store_decimal_as_integer=store_decimal_as_integer,\n\u001b[32m   1982\u001b[39m             **kwargs) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(where):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pyarrow/parquet/core.py:1166\u001b[39m, in \u001b[36mParquetWriter.write_table\u001b[39m\u001b[34m(self, table, row_group_size)\u001b[39m\n\u001b[32m   1160\u001b[39m     msg = (\n\u001b[32m   1161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTable schema does not match schema used to create file: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtable:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtable.schema\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m vs. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.schema\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1163\u001b[39m     )\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pyarrow/_parquet.pyx:2386\u001b[39m, in \u001b[36mpyarrow._parquet.ParquetWriter.write_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] Error writing bytes to file. Detail: [errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "np.save(OUT_DIR / \"X_desc_reduced.npy\", X_desc_reduced)\n",
    "np.save(OUT_DIR / \"X_review_reduced.npy\", X_review_reduced)\n",
    "joblib.dump(tfidf_desc, OUT_DIR / \"tfidf_desc.joblib\")\n",
    "joblib.dump(svd_desc, OUT_DIR / \"svd_desc.joblib\")\n",
    "joblib.dump(tfidf_rev, OUT_DIR / \"tfidf_rev.joblib\")\n",
    "joblib.dump(svd_rev, OUT_DIR / \"svd_rev.joblib\")\n",
    "df_books_text.to_parquet(OUT_DIR / \"df_books_text.parquet\",\n",
    "index=False)\n",
    "\n",
    "title_norm_to_row = {t: i for i, t in\n",
    "enumerate(df_books_text[\"Title_norm\"])}\n",
    "with open(OUT_DIR / \"title_norm_to_row.json\", \"w\") as f:\n",
    "  json.dump({k: int(v) for k, v in title_norm_to_row.items()},\n",
    "f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
